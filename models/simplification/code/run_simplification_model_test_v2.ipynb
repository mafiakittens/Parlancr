{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander_mpa/anaconda3/envs/py27/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]0;IPython: simplification/code\u0007/home/alexander_mpa/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "------------------------------------------------\n",
      "{   'batch_size': 64,\n",
      "    'beam': 1,\n",
      "    'dev': '../data/wiki_matched_short.dev',\n",
      "    'dim_emb': 100,\n",
      "    'dim_y': 200,\n",
      "    'dim_z': 500,\n",
      "    'dropout_keep_prob': 0.5,\n",
      "    'embedding': '',\n",
      "    'filter_sizes': '1,2,3,4,5',\n",
      "    'gamma_decay': 1,\n",
      "    'gamma_init': 0.1,\n",
      "    'gamma_min': 0.1,\n",
      "    'learning_rate': 0.0005,\n",
      "    'load_model': False,\n",
      "    'max_epochs': 40,\n",
      "    'max_seq_length': 25,\n",
      "    'max_train_size': -1,\n",
      "    'model': '../tmp/model',\n",
      "    'n_filters': 128,\n",
      "    'n_layers': 1,\n",
      "    'online_testing': False,\n",
      "    'output': '../tmp/wiki_matched_short.valid',\n",
      "    'rho': 1,\n",
      "    'steps_per_checkpoint': 1000,\n",
      "    'test': '',\n",
      "    'train': '../data/wiki_matched_short.train',\n",
      "    'vocab': '../tmp/wiki_matched_short.vocab'}\n",
      "------------------------------------------------\n",
      "#sents of training file 0: 188735\n",
      "#sents of training file 1: 188735\n",
      "vocabulary size: 26289\n",
      "2018-08-01 22:52:27.355625: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-08-01 22:52:27.470449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-08-01 22:52:27.470910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.90GiB freeMemory: 15.53GiB\n",
      "2018-08-01 22:52:27.470933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n",
      "2018-08-01 22:52:27.780497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-01 22:52:27.780548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n",
      "2018-08-01 22:52:27.780557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n",
      "2018-08-01 22:52:27.780892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15052 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "Creating model with fresh parameters.\n",
      "--------------------epoch 1--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 1000, time 357s, loss 102.49, rec 99.44, adv 3.04, d0 1.04, d1 1.07\n",
      "step 2000, time 716s, loss 94.31, rec 90.58, adv 3.73, d0 0.82, d1 0.91\n",
      "dev loss 87.89, rec 84.46, adv 3.42, d0 0.70, d1 1.29\n",
      "saving model...\n",
      "--------------------epoch 2--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 3000, time 1198s, loss 91.14, rec 87.03, adv 4.11, d0 0.77, d1 0.88\n",
      "step 4000, time 1562s, loss 91.95, rec 87.54, adv 4.41, d0 0.70, d1 0.83\n",
      "step 5000, time 1929s, loss 90.77, rec 86.09, adv 4.69, d0 0.68, d1 0.79\n",
      "dev loss 90.57, rec 84.46, adv 6.11, d0 0.52, d1 0.84\n",
      "--------------------epoch 3--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 6000, time 2418s, loss 90.32, rec 85.27, adv 5.05, d0 0.62, d1 0.73\n",
      "step 7000, time 2786s, loss 91.91, rec 86.37, adv 5.54, d0 0.59, d1 0.71\n",
      "step 8000, time 3158s, loss 91.80, rec 86.26, adv 5.54, d0 0.58, d1 0.71\n",
      "dev loss 88.20, rec 82.89, adv 5.31, d0 0.54, d1 1.04\n",
      "--------------------epoch 4--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 9000, time 3649s, loss 90.92, rec 85.11, adv 5.81, d0 0.55, d1 0.68\n",
      "step 10000, time 4022s, loss 92.79, rec 86.86, adv 5.93, d0 0.55, d1 0.68\n",
      "step 11000, time 4399s, loss 92.91, rec 86.80, adv 6.11, d0 0.51, d1 0.63\n",
      "dev loss 89.46, rec 82.72, adv 6.75, d0 0.58, d1 1.04\n",
      "--------------------epoch 5--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 12000, time 4890s, loss 92.54, rec 86.03, adv 6.51, d0 0.53, d1 0.61\n",
      "step 13000, time 5263s, loss 94.16, rec 87.57, adv 6.58, d0 0.52, d1 0.60\n",
      "step 14000, time 5641s, loss 94.51, rec 87.67, adv 6.84, d0 0.49, d1 0.56\n",
      "dev loss 90.85, rec 84.19, adv 6.66, d0 0.37, d1 0.83\n",
      "--------------------epoch 6--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 15000, time 6135s, loss 94.54, rec 87.38, adv 7.16, d0 0.44, d1 0.55\n",
      "step 16000, time 6509s, loss 96.37, rec 88.94, adv 7.43, d0 0.47, d1 0.53\n",
      "step 17000, time 6887s, loss 96.12, rec 88.82, adv 7.30, d0 0.46, d1 0.53\n",
      "dev loss 90.46, rec 83.77, adv 6.69, d0 0.46, d1 1.05\n",
      "--------------------epoch 7--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 18000, time 7384s, loss 95.55, rec 88.25, adv 7.30, d0 0.45, d1 0.54\n",
      "step 19000, time 7762s, loss 97.99, rec 90.25, adv 7.74, d0 0.43, d1 0.49\n",
      "step 20000, time 8138s, loss 98.40, rec 90.16, adv 8.24, d0 0.40, d1 0.48\n",
      "dev loss 92.41, rec 84.93, adv 7.48, d0 0.40, d1 0.95\n",
      "--------------------epoch 8--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 21000, time 8633s, loss 97.62, rec 89.53, adv 8.09, d0 0.42, d1 0.48\n",
      "step 22000, time 9014s, loss 100.53, rec 92.29, adv 8.23, d0 0.38, d1 0.44\n",
      "step 23000, time 9390s, loss 99.26, rec 90.46, adv 8.79, d0 0.37, d1 0.40\n",
      "dev loss 94.06, rec 85.93, adv 8.12, d0 0.43, d1 1.00\n",
      "--------------------epoch 9--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 24000, time 9888s, loss 99.34, rec 90.76, adv 8.57, d0 0.38, d1 0.44\n",
      "step 25000, time 10268s, loss 103.64, rec 94.43, adv 9.21, d0 0.35, d1 0.40\n",
      "step 26000, time 10645s, loss 99.27, rec 90.61, adv 8.67, d0 0.38, d1 0.43\n",
      "dev loss 95.62, rec 87.19, adv 8.43, d0 0.27, d1 0.78\n",
      "--------------------epoch 10--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 27000, time 11142s, loss 100.92, rec 91.93, adv 8.99, d0 0.35, d1 0.39\n",
      "step 28000, time 11524s, loss 104.35, rec 95.05, adv 9.30, d0 0.34, d1 0.39\n",
      "step 29000, time 11902s, loss 100.59, rec 91.27, adv 9.33, d0 0.32, d1 0.36\n",
      "dev loss 98.56, rec 89.24, adv 9.32, d0 0.25, d1 0.53\n",
      "--------------------epoch 11--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 30000, time 12401s, loss 103.30, rec 93.32, adv 9.98, d0 0.29, d1 0.34\n",
      "step 31000, time 12780s, loss 105.91, rec 95.90, adv 10.02, d0 0.30, d1 0.34\n",
      "step 32000, time 13156s, loss 101.98, rec 92.01, adv 9.98, d0 0.30, d1 0.33\n",
      "dev loss 100.80, rec 90.83, adv 9.97, d0 0.35, d1 0.69\n",
      "--------------------epoch 12--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 33000, time 13658s, loss 105.22, rec 95.11, adv 10.11, d0 0.30, d1 0.33\n",
      "step 34000, time 14037s, loss 106.59, rec 96.22, adv 10.36, d0 0.29, d1 0.29\n",
      "step 35000, time 14415s, loss 104.89, rec 94.30, adv 10.58, d0 0.28, d1 0.30\n",
      "dev loss 99.75, rec 90.03, adv 9.71, d0 0.29, d1 0.53\n",
      "--------------------epoch 13--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 36000, time 14915s, loss 107.80, rec 97.19, adv 10.61, d0 0.28, d1 0.30\n",
      "step 37000, time 15295s, loss 108.44, rec 97.77, adv 10.67, d0 0.27, d1 0.27\n",
      "step 38000, time 15668s, loss 106.58, rec 95.79, adv 10.79, d0 0.28, d1 0.30\n",
      "dev loss 102.20, rec 91.43, adv 10.76, d0 0.25, d1 0.54\n",
      "--------------------epoch 14--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 39000, time 16165s, loss 108.38, rec 97.71, adv 10.67, d0 0.26, d1 0.27\n",
      "step 40000, time 16545s, loss 108.36, rec 97.33, adv 11.03, d0 0.25, d1 0.25\n",
      "step 41000, time 16921s, loss 106.51, rec 95.61, adv 10.90, d0 0.26, d1 0.29\n",
      "dev loss 101.91, rec 90.95, adv 10.96, d0 0.27, d1 0.49\n",
      "--------------------epoch 15--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 42000, time 17420s, loss 109.03, rec 98.07, adv 10.96, d0 0.27, d1 0.30\n",
      "step 43000, time 17803s, loss 108.14, rec 97.04, adv 11.11, d0 0.29, d1 0.28\n",
      "step 44000, time 18178s, loss 103.94, rec 93.65, adv 10.29, d0 0.30, d1 0.29\n",
      "dev loss 101.80, rec 90.45, adv 11.35, d0 0.28, d1 0.69\n",
      "--------------------epoch 16--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 45000, time 18677s, loss 106.69, rec 96.49, adv 10.20, d0 0.30, d1 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46000, time 19057s, loss 106.28, rec 95.82, adv 10.46, d0 0.28, d1 0.31\n",
      "step 47000, time 19435s, loss 104.15, rec 94.12, adv 10.03, d0 0.31, d1 0.34\n",
      "dev loss 97.63, rec 88.30, adv 9.32, d0 0.29, d1 0.77\n",
      "--------------------epoch 17--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 48000, time 19936s, loss 107.47, rec 97.03, adv 10.44, d0 0.29, d1 0.33\n",
      "step 49000, time 20318s, loss 108.01, rec 97.75, adv 10.27, d0 0.28, d1 0.32\n",
      "step 50000, time 20698s, loss 107.32, rec 96.85, adv 10.47, d0 0.27, d1 0.33\n",
      "dev loss 100.18, rec 90.68, adv 9.51, d0 0.22, d1 0.48\n",
      "--------------------epoch 18--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 51000, time 21198s, loss 110.53, rec 99.24, adv 11.28, d0 0.26, d1 0.29\n",
      "step 52000, time 21579s, loss 108.81, rec 98.28, adv 10.53, d0 0.29, d1 0.33\n",
      "step 53000, time 21958s, loss 105.13, rec 95.08, adv 10.05, d0 0.29, d1 0.34\n",
      "dev loss 98.76, rec 89.41, adv 9.36, d0 0.25, d1 0.57\n",
      "--------------------epoch 19--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 54000, time 22452s, loss 109.19, rec 98.71, adv 10.48, d0 0.27, d1 0.32\n",
      "step 55000, time 22829s, loss 108.65, rec 97.98, adv 10.67, d0 0.25, d1 0.28\n",
      "step 56000, time 23203s, loss 106.93, rec 96.12, adv 10.82, d0 0.27, d1 0.31\n",
      "dev loss 99.37, rec 90.36, adv 9.01, d0 0.27, d1 0.41\n",
      "--------------------epoch 20--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 57000, time 23698s, loss 111.87, rec 100.46, adv 11.41, d0 0.25, d1 0.27\n",
      "step 58000, time 24078s, loss 110.36, rec 99.43, adv 10.93, d0 0.26, d1 0.29\n",
      "dev loss 100.26, rec 90.06, adv 10.19, d0 0.29, d1 0.60\n",
      "--------------------epoch 21--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 59000, time 24577s, loss 107.98, rec 96.87, adv 11.11, d0 0.26, d1 0.29\n",
      "step 60000, time 24958s, loss 111.09, rec 99.72, adv 11.37, d0 0.24, d1 0.27\n",
      "step 61000, time 25337s, loss 110.56, rec 99.13, adv 11.43, d0 0.25, d1 0.26\n",
      "dev loss 101.61, rec 90.81, adv 10.80, d0 0.28, d1 0.48\n",
      "--------------------epoch 22--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 62000, time 25830s, loss 107.91, rec 97.31, adv 10.60, d0 0.25, d1 0.31\n",
      "step 63000, time 26203s, loss 111.63, rec 100.34, adv 11.29, d0 0.28, d1 0.29\n",
      "step 64000, time 26577s, loss 110.08, rec 99.38, adv 10.71, d0 0.27, d1 0.28\n",
      "dev loss 100.99, rec 91.08, adv 9.91, d0 0.27, d1 0.53\n",
      "--------------------epoch 23--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 65000, time 27066s, loss 107.95, rec 97.12, adv 10.83, d0 0.27, d1 0.31\n",
      "step 66000, time 27439s, loss 112.46, rec 100.91, adv 11.54, d0 0.24, d1 0.24\n",
      "step 67000, time 27813s, loss 111.94, rec 100.37, adv 11.56, d0 0.21, d1 0.24\n",
      "dev loss 103.78, rec 92.25, adv 11.53, d0 0.26, d1 0.46\n",
      "--------------------epoch 24--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 68000, time 28313s, loss 110.41, rec 98.61, adv 11.79, d0 0.23, d1 0.24\n",
      "step 69000, time 28696s, loss 112.17, rec 100.60, adv 11.57, d0 0.24, d1 0.27\n",
      "step 70000, time 29077s, loss 109.32, rec 98.60, adv 10.72, d0 0.27, d1 0.30\n",
      "dev loss 108.31, rec 94.48, adv 13.83, d0 0.21, d1 0.69\n",
      "--------------------epoch 25--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 71000, time 29575s, loss 109.06, rec 98.19, adv 10.87, d0 0.28, d1 0.31\n",
      "step 72000, time 29957s, loss 111.67, rec 100.31, adv 11.36, d0 0.25, d1 0.26\n",
      "step 73000, time 30337s, loss 111.95, rec 100.68, adv 11.27, d0 0.25, d1 0.28\n",
      "dev loss 101.93, rec 91.89, adv 10.04, d0 0.22, d1 0.59\n",
      "--------------------epoch 26--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 74000, time 30837s, loss 110.05, rec 98.67, adv 11.38, d0 0.25, d1 0.29\n",
      "step 75000, time 31220s, loss 112.22, rec 100.70, adv 11.52, d0 0.25, d1 0.28\n",
      "step 76000, time 31597s, loss 112.25, rec 100.64, adv 11.61, d0 0.24, d1 0.26\n",
      "dev loss 104.49, rec 93.11, adv 11.38, d0 0.22, d1 0.49\n",
      "--------------------epoch 27--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 77000, time 32086s, loss 110.05, rec 98.82, adv 11.23, d0 0.26, d1 0.30\n",
      "step 78000, time 32461s, loss 112.80, rec 101.31, adv 11.49, d0 0.25, d1 0.28\n",
      "step 79000, time 32833s, loss 110.26, rec 98.72, adv 11.54, d0 0.24, d1 0.27\n",
      "dev loss 102.92, rec 91.59, adv 11.33, d0 0.27, d1 0.52\n",
      "--------------------epoch 28--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 80000, time 33324s, loss 109.51, rec 98.41, adv 11.10, d0 0.25, d1 0.28\n",
      "step 81000, time 33700s, loss 114.34, rec 103.05, adv 11.29, d0 0.23, d1 0.23\n",
      "step 82000, time 34072s, loss 111.30, rec 99.55, adv 11.76, d0 0.25, d1 0.27\n",
      "dev loss 104.38, rec 92.91, adv 11.47, d0 0.23, d1 0.64\n",
      "--------------------epoch 29--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 83000, time 34562s, loss 112.18, rec 100.53, adv 11.65, d0 0.22, d1 0.24\n",
      "step 84000, time 34936s, loss 114.15, rec 102.52, adv 11.63, d0 0.23, d1 0.25\n",
      "step 85000, time 35308s, loss 111.65, rec 100.21, adv 11.44, d0 0.25, d1 0.28\n",
      "dev loss 111.02, rec 95.24, adv 15.78, d0 0.25, d1 0.36\n",
      "--------------------epoch 30--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 86000, time 35799s, loss 113.68, rec 102.28, adv 11.40, d0 0.23, d1 0.29\n",
      "step 87000, time 36175s, loss 115.96, rec 104.00, adv 11.95, d0 0.23, d1 0.26\n",
      "step 88000, time 36546s, loss 110.32, rec 98.54, adv 11.78, d0 0.22, d1 0.24\n",
      "dev loss 100.86, rec 90.45, adv 10.41, d0 0.29, d1 0.48\n",
      "--------------------epoch 31--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 89000, time 37037s, loss 112.12, rec 100.44, adv 11.68, d0 0.23, d1 0.24\n",
      "step 90000, time 37411s, loss 115.36, rec 103.25, adv 12.11, d0 0.25, d1 0.24\n",
      "step 91000, time 37782s, loss 110.42, rec 98.94, adv 11.47, d0 0.23, d1 0.28\n",
      "dev loss 102.98, rec 92.72, adv 10.26, d0 0.28, d1 0.50\n",
      "--------------------epoch 32--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 92000, time 38277s, loss 115.08, rec 103.08, adv 12.01, d0 0.23, d1 0.25\n",
      "step 93000, time 38651s, loss 114.65, rec 102.45, adv 12.20, d0 0.21, d1 0.23\n",
      "step 94000, time 39022s, loss 111.10, rec 98.89, adv 12.21, d0 0.23, d1 0.25\n",
      "dev loss 104.94, rec 93.75, adv 11.19, d0 0.24, d1 0.54\n",
      "--------------------epoch 33--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 95000, time 39513s, loss 115.31, rec 103.08, adv 12.22, d0 0.23, d1 0.23\n",
      "step 96000, time 39886s, loss 115.32, rec 102.93, adv 12.39, d0 0.21, d1 0.23\n",
      "step 97000, time 40258s, loss 111.28, rec 99.91, adv 11.37, d0 0.26, d1 0.30\n",
      "dev loss 107.75, rec 95.16, adv 12.59, d0 0.22, d1 0.62\n",
      "--------------------epoch 34--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 98000, time 40748s, loss 115.85, rec 103.73, adv 12.12, d0 0.24, d1 0.26\n",
      "step 99000, time 41123s, loss 115.49, rec 103.78, adv 11.71, d0 0.23, d1 0.26\n",
      "step 100000, time 41494s, loss 113.33, rec 101.07, adv 12.26, d0 0.22, d1 0.22\n",
      "dev loss 104.51, rec 92.20, adv 12.31, d0 0.23, d1 0.45\n",
      "--------------------epoch 35--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 101000, time 41986s, loss 116.45, rec 103.73, adv 12.72, d0 0.22, d1 0.19\n",
      "step 102000, time 42359s, loss 118.72, rec 105.82, adv 12.91, d0 0.21, d1 0.19\n",
      "step 103000, time 42731s, loss 111.61, rec 99.58, adv 12.03, d0 0.24, d1 0.25\n",
      "dev loss 103.41, rec 92.94, adv 10.47, d0 0.21, d1 0.55\n",
      "--------------------epoch 36--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 104000, time 43224s, loss 113.03, rec 100.99, adv 12.04, d0 0.21, d1 0.23\n",
      "step 105000, time 43596s, loss 113.62, rec 101.26, adv 12.36, d0 0.24, d1 0.24\n",
      "step 106000, time 43969s, loss 113.53, rec 101.58, adv 11.95, d0 0.24, d1 0.28\n",
      "dev loss 104.37, rec 93.59, adv 10.79, d0 0.26, d1 0.63\n",
      "--------------------epoch 37--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 107000, time 44461s, loss 113.26, rec 101.85, adv 11.41, d0 0.24, d1 0.26\n",
      "step 108000, time 44835s, loss 112.43, rec 100.71, adv 11.72, d0 0.23, d1 0.25\n",
      "step 109000, time 45206s, loss 111.99, rec 100.11, adv 11.88, d0 0.23, d1 0.25\n",
      "dev loss 105.58, rec 93.40, adv 12.18, d0 0.24, d1 0.45\n",
      "--------------------epoch 38--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 110000, time 45697s, loss 113.82, rec 102.64, adv 11.18, d0 0.27, d1 0.27\n",
      "step 111000, time 46072s, loss 112.80, rec 101.52, adv 11.28, d0 0.27, d1 0.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 112000, time 46444s, loss 111.51, rec 100.39, adv 11.11, d0 0.25, d1 0.28\n",
      "dev loss 101.81, rec 91.19, adv 10.62, d0 0.23, d1 0.60\n",
      "--------------------epoch 39--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 113000, time 46936s, loss 112.29, rec 101.01, adv 11.28, d0 0.24, d1 0.27\n",
      "step 114000, time 47310s, loss 113.95, rec 102.46, adv 11.49, d0 0.26, d1 0.26\n",
      "step 115000, time 47688s, loss 110.05, rec 98.64, adv 11.42, d0 0.26, d1 0.30\n",
      "dev loss 102.42, rec 91.34, adv 11.08, d0 0.30, d1 0.73\n",
      "--------------------epoch 40--------------------\n",
      "learning_rate: 0.0005   gamma: 0.1\n",
      "step 116000, time 48188s, loss 114.71, rec 103.15, adv 11.56, d0 0.25, d1 0.26\n",
      "step 117000, time 48568s, loss 113.52, rec 102.16, adv 11.35, d0 0.26, d1 0.24\n",
      "dev loss 104.08, rec 91.03, adv 13.05, d0 0.23, d1 0.45\n"
     ]
    }
   ],
   "source": [
    "!python style_transfer.py --train ../data/wiki_matched_short.train --dev ../data/wiki_matched_short.dev --output ../tmp/wiki_matched_short.valid --vocab ../tmp/wiki_matched_short.vocab --model ../tmp/model --max_epochs 40 --max_seq_length 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]0;IPython: simplification/code\u0007/home/alexander_mpa/anaconda3/envs/py27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "------------------------------------------------\n",
      "{   'batch_size': 64,\n",
      "    'beam': 8,\n",
      "    'dev': '',\n",
      "    'dim_emb': 100,\n",
      "    'dim_y': 200,\n",
      "    'dim_z': 500,\n",
      "    'dropout_keep_prob': 0.5,\n",
      "    'embedding': '',\n",
      "    'filter_sizes': '1,2,3,4,5',\n",
      "    'gamma_decay': 1,\n",
      "    'gamma_init': 0.1,\n",
      "    'gamma_min': 0.1,\n",
      "    'learning_rate': 0.0005,\n",
      "    'load_model': True,\n",
      "    'max_epochs': 20,\n",
      "    'max_seq_length': 25,\n",
      "    'max_train_size': -1,\n",
      "    'model': '../tmp/model',\n",
      "    'n_filters': 128,\n",
      "    'n_layers': 1,\n",
      "    'online_testing': False,\n",
      "    'output': '../tmp/wiki_matched.test',\n",
      "    'rho': 1,\n",
      "    'steps_per_checkpoint': 1000,\n",
      "    'test': '../data/wiki_matched.test',\n",
      "    'train': '',\n",
      "    'vocab': '../tmp/wiki_matched_short.vocab'}\n",
      "------------------------------------------------\n",
      "vocabulary size: 26289\n",
      "2018-08-02 14:19:34.643966: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-08-02 14:19:34.750032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2018-08-02 14:19:34.750469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: \n",
      "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 15.90GiB freeMemory: 15.53GiB\n",
      "2018-08-02 14:19:34.750492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0\n",
      "2018-08-02 14:19:35.053021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-08-02 14:19:35.053071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 \n",
      "2018-08-02 14:19:35.053079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N \n",
      "2018-08-02 14:19:35.053414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15052 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
      "Loading model from ../tmp/model\n",
      "INFO:tensorflow:Restoring parameters from ../tmp/model\n",
      "test loss 133.74, rec 130.40, adv 3.34, d0 1.46, d1 1.80\n"
     ]
    }
   ],
   "source": [
    "!python style_transfer.py --test ../data/wiki_matched.test --output ../tmp/wiki_matched.test --vocab ../tmp/wiki_matched_short.vocab --model ../tmp/model --load_model true --beam 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
