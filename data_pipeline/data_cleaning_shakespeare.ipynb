{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/chadharness/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# The future\n",
    "#from __future__ import print_function, division, absolute_import\n",
    "\n",
    "# Data wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob as glob\n",
    "import pickle as pickle\n",
    "\n",
    "# Numpy shorthand stuff\n",
    "from numpy import array\n",
    "\n",
    "# NLTK shorthand stuff\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import TweetTokenizer, RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "\n",
    "# SK-learn library for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrowed some functions from the w266 utils.py file\n",
    "# Miscellaneous helpers\n",
    "def flatten(list_of_lists):\n",
    "    \"\"\"Flatten a list-of-lists into a single list.\"\"\"\n",
    "    return list(itertools.chain.from_iterable(list_of_lists))\n",
    "\n",
    "\n",
    "# Word processing functions\n",
    "def canonicalize_digits(word):\n",
    "    if any([c.isalpha() for c in word]): return word\n",
    "    word = re.sub(\"\\d\", \"DG\", word)\n",
    "    if word.startswith(\"DG\"):\n",
    "        word = word.replace(\",\", \"\") # remove thousands separator\n",
    "        #word = re.sub(r\"(DG)+\", \"DG\", word)\n",
    "    return word\n",
    "\n",
    "\n",
    "def canonicalize_word(word, wordset=None, digits=True):\n",
    "    #word = re.sub(r\":\",\"\",word)\n",
    "    #word = re.sub(r\"https?\",\"\",word)\n",
    "    #word = re.sub(r\"\\/\",\"\",word)\n",
    "    #word = re.sub(r\"@\",\"\",word)\n",
    "    #word = re.sub(r\"/\\U0001.?'\",\"\",word)\n",
    "    #replace hyperlinks with one instance of \"postedhyperlinkvalue\"\n",
    "    word = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w\\.-]*)*\\/?\\S*\", \"postedhyperlinkvalue\", word)\n",
    "    word = re.sub(r\"(postedhyperlinkvalue)+\", \"postedhyperlinkvalue\", word)\n",
    "    #only lower case words (2 letters or longer) that are not all upper case\n",
    "    if not word.isupper() or len(word) == 1:\n",
    "        word = word.lower()\n",
    "    #replace things like haha with ha\n",
    "    word = re.sub(r\"([a-z]{2,})\\1{2,}\", r\"\\1\", word)\n",
    "    #replace any three consecutive, identical letters with two instances of that letter\n",
    "    word = re.sub(r\"([a-z])\\1{2,}\", r\"\\1\\1\", word)\n",
    "    #replace any two consecutive, identical consonants at the beginning of a string with one of that consonant\n",
    "    word = re.sub(r\"(^[^aeiou])\\1{1,}\", r\"\\1\", word)\n",
    "    \n",
    "    #replace digits with a stand-in token\n",
    "    if digits:\n",
    "        if (wordset != None) and (word in wordset): return word\n",
    "        word = canonicalize_digits(word) # try to canonicalize numbers\n",
    "    if (wordset == None) or (word in wordset):\n",
    "        return word\n",
    "    else:\n",
    "        return constants.UNK_TOKEN\n",
    "\n",
    "    \n",
    "def canonicalize_words(words, **kw):\n",
    "    return [canonicalize_word(word, **kw) for word in words]\n",
    "\n",
    "\n",
    "# Made some helper functions of our own\n",
    "from nltk.stem import PorterStemmer   \n",
    "def stem_sentence(token_sent, stemmer=PorterStemmer()):\n",
    "    stem_token_sent = []\n",
    "    for word in token_sent:\n",
    "        stem_token_sent.append(stemmer.stem(word))\n",
    "    return stem_token_sent\n",
    "\n",
    "\n",
    "def sent_plus_word_tokenize(series):\n",
    "    sentences = []\n",
    "    words = []\n",
    "    \n",
    "    for comment in series:\n",
    "        sentences.append(sent_tokenize(comment))\n",
    "    \n",
    "    flat_sentences = [item for sublist in sentences for item in sublist]\n",
    "    \n",
    "    for comment_sentence in flat_sentences:\n",
    "        words.append(word_tokenize(comment_sentence))\n",
    "    \n",
    "    return sentences, words\n",
    "\n",
    "\n",
    "def make_data(data, target='', commentfield='', tokenizer=TweetTokenizer(), canonize=True, stem=True):      \n",
    "    # Separate comments\n",
    "    comments = data.loc[:, commentfield]\n",
    "    #comments = data.loc[:, 'comment_body']\n",
    "    #labels = data.loc[:, target]\n",
    "    \n",
    "    # Convert to list\n",
    "    comment_list = comments.values.tolist()\n",
    "    \n",
    "    # Tokenize comments\n",
    "    tokenizer = tokenizer\n",
    "    # A list of lists of tokenized sentences: word == string/token; sentence == list of string/tokens\n",
    "    tokenized_sentences = [tokenizer.tokenize(sentence) for sentence in comment_list]\n",
    "    #tokenized_sentences_x = [tokenizer.tokenize(sentence) for sentence in comment_list]\n",
    "    #tokenized_sentences = []\n",
    "    #sentence = []\n",
    "    #last_tok = ''\n",
    "    #for comment in tokenized_sentences_x:\n",
    "    #    for tok in comment:\n",
    "    #        if last_tok in ('http', 'https',':','http:','https:','@'):\n",
    "    #            tok = last_tok + tok\n",
    "    #        if tok in ('http', 'https',':', '@'):\n",
    "    #            last_tok = tok\n",
    "    #        else:\n",
    "    #            last_tok = ''\n",
    "    #            sentence.append(tok)\n",
    "    #    tokenized_sentences.append(sentence)\n",
    "    \n",
    "    if stem:\n",
    "        # Stem words\n",
    "        comments_stem = []\n",
    "        for sentence in tokenized_sentences:\n",
    "            x_tokens_stem = stem_sentence(token_sent=sentence, stemmer=PorterStemmer())\n",
    "            comments_stem.append(x_tokens_stem)\n",
    "        tokenized_sentences = comments_stem\n",
    "    \n",
    "    if canonize:\n",
    "        # Canonize words\n",
    "        comments_canon = []\n",
    "        for sentence in tokenized_sentences:\n",
    "            x_tokens_canon = canonicalize_words(sentence)\n",
    "            comments_canon.append(x_tokens_canon)\n",
    "        # A list of lists of scrubbed tokens; token == word, list == sentence\n",
    "        tokenized_sentences = comments_canon\n",
    "    \n",
    "    x_tokens = tokenized_sentences  \n",
    "    #return comments, x_tokens, labels\n",
    "    return comments, x_tokens\n",
    "\n",
    "\n",
    "def rawlist_to_xtokens(rawlist=['default arg'], vocab_list=[]):\n",
    "    xtokens = []\n",
    "    for rawstring in rawlist:\n",
    "        xtoken = list(filter(lambda x: x in vocab_list, rawstring.split()))\n",
    "        xtokens.append(xtoken)   \n",
    "    return xtokens\n",
    "\n",
    "\n",
    "def xtoken_to_raw(xtoken=['default','arg']):  \n",
    "    raw_text_string = ' '.join(xtoken)\n",
    "    return raw_text_string\n",
    "\n",
    "\n",
    "def raw_to_xtoken(raw_string='default arg'):\n",
    "    xtoken = raw_string.split()\n",
    "    return xtoken\n",
    "\n",
    "\n",
    "def model_diagnostics(model, data, labels, target_names, random=False, test_size=0.10, random_state=42):\n",
    "    \n",
    "    # Split into test and train\n",
    "    # Designate random test_size% of data (rounded up to next obs) as test data\n",
    "    if random:\n",
    "        train_data, test_data, train_labels, test_labels = train_test_split(data, labels, \n",
    "                                                                            test_size=test_size, \n",
    "                                                                            random_state=random_state)\n",
    "    # Designate last test_size% of data (rounded up to next obs) as test data \n",
    "    else:\n",
    "        idx = round(test_size*len(data))\n",
    "        test_data = data[-idx:]\n",
    "        test_labels = labels[-idx:]\n",
    "    \n",
    "    \n",
    "    pred_labels = model.predict_classes(test_data)\n",
    "    \n",
    "    print(\"Test data length is: \", len(test_data))\n",
    "    print(\"Test label length is: \", len(test_labels))\n",
    "    print(\"Pred label length is: \", len(pred_labels))\n",
    "    \n",
    "    confusionMatrix = metrics.confusion_matrix(test_labels, pred_labels)\n",
    "    classificationReport = classification_report(test_labels, pred_labels, target_names=target_names)\n",
    "    \n",
    "    return confusionMatrix, classificationReport\n",
    "\n",
    "\n",
    "# Function to aggregate all of the comments for a given subreddit(s)\n",
    "\n",
    "# Data location example: reddit data for March 2018 downloaded to ~/parlancr/data/reddit/2018_03/\n",
    "# File names: reddit_2018_03000000000000.csv - reddit_2018_03000000000047.csv\n",
    "\n",
    "def export_subreddits(subs):\n",
    "    \n",
    "    selected_subreddits = pd.DataFrame()\n",
    "    file_stem = './data/reddit/*/reddit_*.csv'\n",
    "    \n",
    "    for f in sorted(glob.glob(file_stem)):\n",
    "        \n",
    "        print('Loading comments from: ', f)\n",
    "        partition_comments = pd.read_csv(f)\n",
    "        selected_subreddits = selected_subreddits.append(partition_comments[partition_comments['subreddit'].isin(subs)], ignore_index = True)\n",
    "        \n",
    "    return selected_subreddits\n",
    "\n",
    "\n",
    "def build_model_input(pandas_df, commentfield, post_length, sent_length, tokenizer=TweetTokenizer()):\n",
    "    \n",
    "    sentences, tokens = sent_plus_word_tokenize(pandas_df[commentfield].dropna().values)\n",
    "    \n",
    "    sents = [sents for line in sentences for sents in line if len(line) <= post_length]\n",
    "    \n",
    "    sents_pd = pd.DataFrame({commentfield:sents})\n",
    "    \n",
    "    comments, x_tokens = make_data(sents_pd, commentfield=commentfield, canonize=True, stem=False, tokenizer=tokenizer)\n",
    "    \n",
    "    tokens = [sent for sent in x_tokens if len(sent) <= sent_length]\n",
    "    \n",
    "    raw_list = list(map(xtoken_to_raw, tokens))\n",
    "    \n",
    "    pd_final = pd.DataFrame({commentfield:raw_list})\n",
    "    \n",
    "    #train, validate, test = np.split(pd_final.sample(frac=1), [int(.6*len(pd_final)), int(.8*len(pd_final))])\n",
    "    \n",
    "    #return train, validate, test, pd_final\n",
    "    return pd_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chadharness/w210/Parlancr/data_pipeline\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_modern = pd.read_csv('../../Shakespearizing-Modern-English/data/test.modern.nltktok', sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A jumbled confession can only receive a jumble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love rich Capulet's daughter .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We're bound to each other in every possible wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'll tell you more later about when and where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Holy Saint Francis , this is a drastic change !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  A jumbled confession can only receive a jumble...\n",
       "1                   I love rich Capulet's daughter .\n",
       "2  We're bound to each other in every possible wa...\n",
       "3  I'll tell you more later about when and where ...\n",
       "4    Holy Saint Francis , this is a drastic change !"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_modern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1462\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_modern.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_comments, x_tokens = make_data(shakespeare_modern, commentfield=0, canonize=True, stem=False, tokenizer=TweetTokenizer())\n",
    "    \n",
    "tokens = [sent for sent in x_tokens if len(sent) <= 112]\n",
    "    \n",
    "raw_list = list(map(xtoken_to_raw, tokens))\n",
    "    \n",
    "mod_final = pd.DataFrame({0:raw_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a jumbled confession can only receive a jumble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love rich capulet's daughter .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we're bound to each other in every possible wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i'll tell you more later about when and where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>holy saint francis , this is a drastic change !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  a jumbled confession can only receive a jumble...\n",
       "1                   i love rich capulet's daughter .\n",
       "2  we're bound to each other in every possible wa...\n",
       "3  i'll tell you more later about when and where ...\n",
       "4    holy saint francis , this is a drastic change !"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1462\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_pd = build_model_input(pandas_df=shakespeare_modern, commentfield=0, post_length=10, sent_length=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>now , you lie there on the path .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she said if she were interested in someone , i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>besides , she treats me more respectfully than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what's the obvious conclusion from that ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>just think , i could be count malvolio !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                  now , you lie there on the path .\n",
       "1  she said if she were interested in someone , i...\n",
       "2  besides , she treats me more respectfully than...\n",
       "3          what's the obvious conclusion from that ?\n",
       "4           just think , i could be count malvolio !"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_original = pd.read_csv('../../Shakespearizing-Modern-English/data/test.original.nltktok', sep=\"\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lie thou there ( throwing down a letter ) , fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maria once told me she did affect me , and I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Besides , she uses me with a more exalted resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What should I think on 't ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To be Count Malvolio !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  Lie thou there ( throwing down a letter ) , fo...\n",
       "1  Maria once told me she did affect me , and I h...\n",
       "2  Besides , she uses me with a more exalted resp...\n",
       "3                        What should I think on 't ?\n",
       "4                             To be Count Malvolio !"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_original.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_comments, x_tokens = make_data(shakespeare_original, commentfield=0, canonize=True, stem=False, tokenizer=TweetTokenizer())\n",
    "    \n",
    "tokens = [sent for sent in x_tokens if len(sent) <= 156]\n",
    "    \n",
    "raw_list = list(map(xtoken_to_raw, tokens))\n",
    "    \n",
    "orig_final = pd.DataFrame({0:raw_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie thou there ( throwing down a letter ) , fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maria once told me she did affect me , and i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>besides , she uses me with a more exalted resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what should i think on ' t ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to be count malvolio !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  lie thou there ( throwing down a letter ) , fo...\n",
       "1  maria once told me she did affect me , and i h...\n",
       "2  besides , she uses me with a more exalted resp...\n",
       "3                       what should i think on ' t ?\n",
       "4                             to be count malvolio !"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_pd = build_model_input(pandas_df=shakespeare_original, commentfield=0, post_length=10, sent_length=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lie thou there ( throwing down a letter ) , fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maria once told me she did affect me , and i h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>besides , she uses me with a more exalted resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what should i think on ' t ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to be count malvolio !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  lie thou there ( throwing down a letter ) , fo...\n",
       "1  maria once told me she did affect me , and i h...\n",
       "2  besides , she uses me with a more exalted resp...\n",
       "3                       what should i think on ' t ?\n",
       "4                             to be count malvolio !"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1251\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_pd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>be you his eunuch , and your mute i'll be .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0\n",
       "26  be you his eunuch , and your mute i'll be ."
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_pd.iloc[[26]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>you can be a eunuch , but i'll be mute .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0\n",
       "26  you can be a eunuch , but i'll be mute ."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_pd.iloc[[26]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_final.to_csv('../../data/shakes_mod.train.0', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_final.to_csv('../../data/shakes_mod.valid.1', sep='\\t', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
